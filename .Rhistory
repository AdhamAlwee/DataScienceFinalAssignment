Copy_of_Ride_Sharing_Dataset$hour <- hour(as.POSIXct(Copy_of_Ride_Sharing_Dataset$'Request Time', format="%Y-%m-%d %H:%M:%S"))
#Analyze ride frequency by day of the week and/or hour of the day.
#load necessary libs
library(tidyverse)
library(lubridate)
#2. Temporal Analysis
# Convert 'Request Time' to datetime and extract the hour
Copy_of_Ride_Sharing_Dataset$hour <- hour(as.POSIXct(Copy_of_Ride_Sharing_Dataset$'Request Time', format="%Y-%m-%d %H:%M:%S"))
#Analyze ride frequency by day of the week and/or hour of the day.
# Plot the histogram Number of Rides per hour
ggplot(Copy_of_Ride_Sharing_Dataset, aes(x = hour)) +  # âœ… Fix here: Pass the dataset as the first argument
geom_histogram(binwidth = 1, fill = "blue", color = "black") +
labs(title = "Number of Rides by Hour", x = "Hour of the Day", y = "Number of Rides") +
theme_minimal()
#Check if public holidays affect ride frequency and fares.
Copy_of_Ride_Sharing_Dataset$'Public Holiday' <- as.factor(Copy_of_Ride_Sharing_Dataset$'Public Holiday')
#Check if public holidays affect ride frequency and fares.
Copy_of_Ride_Sharing_Dataset$'Public Holiday' <- as.factor(Copy_of_Ride_Sharing_Dataset$'Public Holiday')
#Compare Ride Frequency on Holidays vs. Non-Holidays
ride_counts <- Copy_of_Ride_Sharing_Dataset %>%
group_by(`Public Holiday`) %>%
summarise(Ride_Count = n())
print(ride_counts)
ggplot(ride_counts, aes(x = `Public Holiday`, y = Ride_Count, fill = `Public Holiday`)) +
geom_bar(stat = "identity") +
labs(title = "Ride Frequency on Public Holidays vs. Non-Holidays", x = "Public Holiday", y = "Number of Rides") +
theme_minimal()
#3. Geospatial Analysis
#Map pickup and dropoff locations to identify common hotspots.
#Heatmap of pickup locations
ggplot(Copy_of_Ride_Sharing_Dataset, aes(x = `Longitude Pickup`, y = `Latitude Pickup`)) +
geom_density_2d_filled() +
theme_minimal() +
labs(title = "Heatmap of Pickup Locations")
#Compare ride distances across different locations.
#Heatmap of dropoff locations
ggplot(Copy_of_Ride_Sharing_Dataset, aes(x = `Longtitude Dropoff`, y = `Latitude Dropoff`)) +
geom_density_2d_filled() +
theme_minimal() +
labs(title = "Heatmap of Dropoff Locations")
# Lab 8a - Built-ins datasets & Data Visualization in R
# 1. Using sample datasets from library
# 1.1 To see the list of pre-loaded data
data()
# 1.2 Loading the dataset
# Load whole dataset
data(mtcars)
# Print the first 10 rows
print(head(mtcars, 10))
# Store only 2 columns in a variable
input <- mtcars[, c('mpg', 'cyl')]
# Print the first 5 rows
print(head(input))
# 2. Visualizing basic plots
# 2.1 Demonstration of the image-like graphics built-ins of R
demo(graphics)
# Give the chart file a name
png(file = "city.png")
# Plot the chart
pie(x, labels)
# Run in R Console
2+3
print("Hello World!")
# Run in R Script named test.R
# My first program in R Programming
myString <- "Hello, World!"
print(myString)
var.1 <- 5
var_1 <- 7
x <- 1
print(ls())
print(ls(pattern="var"))
# Arithmetic Operations
f <- 3
height <- x
Weight <- 2
b <- 12
c <- 5
print(f+3)
print(height-x)
print(Weight*2)
print(b*2)
print(c^5)
m <- height/100
print(Weight/(m**2))
BMI <- Weight/(m**2)
print(BMI)
print(b%%2)
print(c%%2)
name <- readline(prompt="Enter name: ")
# Convert character to numeric
age <- as.numeric(age)
name <- readline(prompt="Enter name: ")
# Convert character to numeric
age <- as.numeric(age)
print(ls())
age <- readline(prompt="Enter age: ")
name <- readline(prompt="Enter name: ")
age <- as.numeric(age)
name <- readline(prompt="Enter name: ")
age <- as.numeric(age)
21
print(paste("Hi,", name, "this year you are", age, "years old."))
age <- readline(prompt="Enter age: ")
print(paste("Hi,", name, "this year you are", age, "years old."))
# Simple R Code
# Run in R Console
2+3
print("Hello World!")
# Run in R Script named test.R
# My first program in R Programming
myString <- "Hello, World!"
print(myString)
# R Variables
var.1 <- 5
var_1 <- 7
x <- 1
print(ls())
print(ls(pattern="var"))
# Arithmetic Operations
f <- 3
height <- x
Weight <- 2
b <- 12
c <- 5
print(f+3)
print(height-x)
print(Weight*2)
print(b*2)
print(c^5)
m <- height/100
print(Weight/(m**2))
BMI <- Weight/(m**2)
print(BMI)
print(b%%2)
print(c%%2)
# User Input
name <- readline(prompt="Enter name: ")
# Convert character to numeric
age <- as.numeric(age)
print(paste("Hi,", name, "this year you are", age, "years old."))
# Extra
?paste
demo(graphics)
# Task 1: Vector Operations
# 1.1 Vector Construction
# Creating sequences and observing behavior
v <- 5:13
print(v)  # Creates a sequence from 5 to 13
v <- 6.6:12.6
print(v)  # Creates a sequence from 6.6 to 12.6
v <- 3.8:11.4
print(v)  # The last value is discarded as it does not belong to the sequence
print(seq(5, 9, by = 0.4))  # Sequence incremented by 0.4
# Mixing types in a vector converts all elements to characters
s <- c('apple', 'red', 5, TRUE)
print(s)
# 1.2 Accessing Vector Elements
t <- c("Sun", "Mon", "Tue", "Wed", "Thurs", "Fri", "Sat")
u <- t[c(2,3,6)]  # Accessing specific elements
print(u)
v <- t[c(TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE)]  # Logical indexing
print(v)
x <- t[c(-2,-5)]  # Negative indexing to exclude elements
print(x)
y <- t[c(0,0,0,0,0,0,1)]  # 0/1 indexing
print(y)
# Conclusion: Vectors can be accessed using position, logical indexing, and negative indexing.
# 1.3 Vector Manipulation
v1 <- c(3,8,4,5,0,11)
v2 <- c(4,11,0,8,1,2)
print(v1 + v2)  # Addition
print(v1 - v2)  # Subtraction
print(v1 * v2)  # Multiplication
print(v1 / v2)  # Division
# Conclusion: Vector operations are element-wise, meaning operations occur between corresponding elements.
# 1.4 Vector Element Recycling
v1 <- c(3,8,4,5,0,11)
v2 <- c(4,11)
print(v1 + v2)  # Recycling smaller vector to match length
print(v1 - v2)
# Conclusion: If vectors are of different lengths, the shorter vector is recycled to match the longer one.
# 1.5 Vector Element Sorting
v <- c(3,8,4,5,0,11, -9, 304)
print(sort(v))  # Ascending order
print(sort(v, decreasing = TRUE))  # Descending order
# Sorting character vectors
v <- c("Red", "Blue", "yellow", "violet")
print(sort(v))  # Lexicographic order
print(sort(v, decreasing = TRUE))  # Reverse lexicographic order
# Conclusion: Sorting works on numeric and character vectors. Characters follow alphabetical order.
# 2.1 List Construction
list_data <- list("Red", "Green", c(21,32,11), TRUE, 51.23, 119.1)
print(list_data)
# 2.2 Naming List Elements
list_data <- list(c("Jan", "Feb", "Mar"), list("green", 12.3))
names(list_data) <- c("1st_Quarter", "A_Inner_list")
print(list_data)
# 2.3 Accessing List Elements
print(list_data[1])  # Accessing first element
print(list_data[2])  # Accessing second element (which is also a list)
print(list_data$A_Inner_list)  # Access using element name
print(which(list_data$`1st_Quarter` == "Feb"))  # Find index of value
# 2.4 List Manipulation
list_data[3] <- "New_element"  # Adding new element
print(list_data[3])
list_data[3] <- NULL  # Removing element
print(list_data[3])
list_data[2] <- "updated_element"  # Updating element
print(list_data[2])
# Conclusion: Lists allow adding, removing,
# Activity 1: Create a sequence of 20 numbers and calculate their squares
numbers <- seq(1, 20)  # Create a sequence from 1 to 20
squares <- numbers^2   # Compute the square of each number
print(squares)         # Display the results
# Activity 2: Display num1 and num2 with specific decimal points
num1 <- 0.956786
num2 <- 7.8345901
cat("num1 rounded to 2 decimal places:", round(num1, 2), "\n")
cat("num2 rounded to 3 decimal places:", round(num2, 3), "\n")
# Activity 3: Calculate and display the area of a circle
radius <- as.numeric(readline("Enter the radius of the circle: ")) # Get user input
cat("The area of the circle is:", area, "\n")  # Display the result
# Activity 1: Create a sequence of 20 numbers and calculate their squares
numbers <- seq(1, 20)  # Create a sequence from 1 to 20
squares <- numbers^2   # Compute the square of each number
print(squares)         # Display the results
# Activity 2: Display num1 and num2 with specific decimal points
num1 <- 0.956786
num2 <- 7.8345901
cat("num1 rounded to 2 decimal places:", round(num1, 2), "\n")
cat("num2 rounded to 3 decimal places:", round(num2, 3), "\n")
# Activity 3: Calculate and display the area of a circle
radius <- as.numeric(readline("Enter the radius of the circle: ")) # Get user input
cat("The area of the circle is:", area, "\n")  # Display the result
area <- pi * radius^2  # Calculate the area
# Activity 1: Create a sequence of 20 numbers and calculate their squares
numbers <- seq(1, 20)  # Create a sequence from 1 to 20
squares <- numbers^2   # Compute the square of each number
print(squares)         # Display the results
# Activity 2: Display num1 and num2 with specific decimal points
num1 <- 0.956786
num2 <- 7.8345901
cat("num1 rounded to 2 decimal places:", round(num1, 2), "\n")
cat("num2 rounded to 3 decimal places:", round(num2, 3), "\n")
radius <- as.numeric(readline("Enter the radius of the circle: ")) # Get user input
area <- pi * radius^2  # Calculate the area
cat("The area of the circle is:", area, "\n")  # Display the result
print("hello world")
gc()
library(shiny)
library(ggplot2)
library(dplyr)
library(tidyr)
library(stringr)
library(tm)
library(proxy)
setwd("C:/Users/user/OneDrive - Universiti Teknologi PETRONAS/Jan 25/Data Science/Project Assignment/DataScienceFinalAssignment")
getwd()
movies_data <- read.csv("datasets/movies.csv")
check_missing_data <- function(data) {
missing_counts <- colSums(is.na(data))
missing_summary <- data.frame(Column = names(data), Missing_Values = missing_counts)
missing_summary <- missing_summary[missing_summary$Missing_Values > 0, ]
if (nrow(missing_summary) == 0) print("No missing values found!") else print(missing_summary)
return(missing_summary)
}
check_missing_data(movies_data)
# Function to recommend movies using TF-IDF
recommend_movies_tfidf <- function(data, movie_title, num_recommendations = 10) {
if (!"title" %in% colnames(data) || !"genres" %in% colnames(data)) {
stop("The dataset must contain 'title' and 'genres' columns")
}
# Create a corpus from genres
corpus <- VCorpus(VectorSource(data$genres))
# Apply TF-IDF transformation
dtm <- TermDocumentMatrix(corpus, control = list(weighting = weightTfIdf))
tfidf_matrix <- t(as.matrix(dtm))  # Transpose so movies are rows
# Ensure movie titles match the TF-IDF matrix order
if (nrow(tfidf_matrix) != nrow(data)) {
stop("Mismatch: TF-IDF matrix and dataset row counts differ.")
}
rownames(tfidf_matrix) <- data$title  # Assign movie titles as row names
# Find the index of the input movie
movie_index <- which(rownames(tfidf_matrix) == movie_title)
if (length(movie_index) == 0) {
stop("Movie not found in dataset")
}
# Compute cosine similarity
similarity_scores <- proxy::dist(tfidf_matrix, method = "cosine")
similarity_matrix <- as.matrix(similarity_scores)  # Convert to matrix
# Extract similarity scores for the input movie
movie_similarities <- similarity_matrix[movie_index, , drop = FALSE]
# Get top recommendations (excluding the input movie itself)
recommended_indices <- order(movie_similarities)[2:(num_recommendations + 1)]
recommendations <- rownames(tfidf_matrix)[recommended_indices]
print("Recommended Movies:")
print(recommendations)
return(recommendations)
}
recommend_movies_tfidf(movies_data, "Toy Story (1995)", 2)
# Function to recommend movies using TF-IDF
recommend_movies_tfidf <- function(data, movie_title, num_recommendations = 10) {
if (!"title" %in% colnames(data) || !"genres" %in% colnames(data)) {
stop("The dataset must contain 'title' and 'genres' columns")
}
# Create a corpus from genres
corpus <- VCorpus(VectorSource(data$genres))
# Apply TF-IDF transformation
dtm <- TermDocumentMatrix(corpus, control = list(weighting = weightTfIdf))
tfidf_matrix <- t(as.matrix(dtm))  # Transpose so movies are rows
# Ensure movie titles match the TF-IDF matrix order
if (nrow(tfidf_matrix) != nrow(data)) {
stop("Mismatch: TF-IDF matrix and dataset row counts differ.")
}
rownames(tfidf_matrix) <- data$title  # Assign movie titles as row names
# Find the index of the input movie
movie_index <- which(rownames(tfidf_matrix) == movie_title)
if (length(movie_index) == 0) {
stop("Movie not found in dataset")
}
# Compute cosine similarity
similarity_scores <- proxy::dist(tfidf_matrix, method = "cosine")
similarity_matrix <- as.matrix(similarity_scores)  # Convert to matrix
# Extract similarity scores for the input movie
movie_similarities <- similarity_matrix[movie_index, , drop = FALSE]
# Get top recommendations (excluding the input movie itself)
recommended_indices <- order(movie_similarities)[2:(num_recommendations + 1)]
recommendations <- rownames(tfidf_matrix)[recommended_indices]
print("Recommended Movies:")
return(recommendations)
}
recommend_movies_tfidf(movies_data, "Toy Story (1995)", 2)
library(shiny)
library(ggplot2)
library(dplyr)
library(tidyr)
library(stringr)
library(tm)
library(proxy)
library(bslib)
library(rsconnect)
setwd("C:/Users/user/Desktop/DataScienceFinalAssignment")
getwd()
movies_data <- read.csv("datasets/movies.csv")
ratings_data <- read.csv("datasets/ratings.csv")
# Function to check missing data
check_missing_data <- function(data) {
missing_counts <- colSums(is.na(data))
missing_summary <- data.frame(Column = names(data), Missing_Values = missing_counts)
missing_summary <- missing_summary[missing_summary$Missing_Values > 0, ]
if (nrow(missing_summary) == 0) print("No missing values found!") else print(missing_summary)
return(missing_summary)
}
# Function to check duplicate rows in the dataset
check_duplicates <- function(data, key_columns) {
duplicate_rows <- data %>%
group_by(across(all_of(key_columns))) %>%
filter(n() > 1)
if (nrow(duplicate_rows) == 0) {
print("No duplicate rows found!")
} else {
print(paste("Number of duplicate rows:", nrow(duplicate_rows)))
print(head(duplicate_rows))
}
return(duplicate_rows)
}
# Check missing values and duplicates in datasets
check_missing_data(movies_data)
check_missing_data(ratings_data)
check_duplicates(movies_data, c("movieId", "title"))
check_duplicates(ratings_data, c("userId", "movieId", "rating"))
#most common genre
genre_analysis <- movies_data %>%
separate_rows(genres, sep = "\\|") %>%
count(genres, sort = TRUE)
ggplot(genre_analysis, aes(x = reorder(genres, n), y = n)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Most Common Movie Genres", x = "Genre", y = "Count")
# Function to analyze distribution of movies by release year
movies_data$year <- as.numeric(str_extract(movies_data$title, "\\d{4}(?=\\))"))
year_distribution <- movies_data %>% count(year)
ggplot(year_distribution, aes(x = year, y = n)) +
geom_line(color = "blue") +
labs(title = "Number of Movies Released Per Year", x = "Year", y = "Count")
# Function to analyze distribution of ratings
rating_distribution <- ratings_data %>% count(rating)
ggplot(rating_distribution, aes(x = rating, y = n)) +
geom_bar(stat = "identity", fill = "red") +
labs(title = "Distribution of Ratings", x = "Rating", y = "Count")
# Function to find most-rated movies
most_rated_movies <- ratings_data %>%
count(movieId, sort = TRUE) %>%
top_n(10, n) %>%
left_join(movies_data, by = "movieId")
ggplot(most_rated_movies, aes(x = reorder(title, n), y = n)) +
geom_bar(stat = "identity", fill = "purple") +
coord_flip() +
labs(title = "Top 10 Most-Rated Movies", x = "Movie", y = "Number of Ratings")
# Function to recommend movies using TF-IDF
recommend_movies_tfidf <- function(data, movie_title, num_recommendations = 10) {
if (!"title" %in% colnames(data) || !"genres" %in% colnames(data)) {
stop("The dataset must contain 'title' and 'genres' columns")
}
# Create a corpus from genres
corpus <- VCorpus(VectorSource(data$genres))
# Apply TF-IDF transformation
dtm <- TermDocumentMatrix(corpus, control = list(weighting = weightTfIdf))
tfidf_matrix <- t(as.matrix(dtm))  # Transpose so movies are rows
# Ensure movie titles match the TF-IDF matrix order
if (nrow(tfidf_matrix) != nrow(data)) {
stop("Mismatch: TF-IDF matrix and dataset row counts differ.")
}
rownames(tfidf_matrix) <- data$title  # Assign movie titles as row names
# Find the index of the input movie
movie_index <- which(rownames(tfidf_matrix) == movie_title)
if (length(movie_index) == 0) {
stop("Movie not found in dataset")
}
# Compute cosine similarity
similarity_scores <- proxy::dist(tfidf_matrix, method = "cosine")
similarity_matrix <- as.matrix(similarity_scores)  # Convert to matrix
# Extract similarity scores for the input movie
movie_similarities <- similarity_matrix[movie_index, , drop = FALSE]
# Get top recommendations (excluding the input movie itself)
recommended_indices <- order(movie_similarities)[2:(num_recommendations + 1)]
recommendations <- rownames(tfidf_matrix)[recommended_indices]
print("Recommended Movies:")
return(recommendations)
}
calculate_precision_recall <- function(recommendations, ratings_data, movies_data, threshold = 4.0) {
# Merge ratings_data with movies_data to get movie titles
ratings_with_titles <- merge(ratings_data, movies_data, by = "movieId")
# Display recommended movies before evaluation
print("Recommended Movies Before Evaluation:")
print(recommendations)
# Extract movies with ratings >= threshold
relevant_movies <- ratings_with_titles[ratings_with_titles$rating >= threshold, "title"]
# Handle case where no relevant movies exist
if (length(relevant_movies) == 0) {
warning("No movies meet the rating threshold. Recall is set to NA.")
recall <- NA
} else {
retrieved_relevant <- sum(recommendations %in% relevant_movies)
recall <- retrieved_relevant / length(relevant_movies)
}
# Handle case where no recommendations are made
if (length(recommendations) == 0) {
warning("No recommendations were made. Precision is set to NA.")
precision <- NA
} else {
retrieved_relevant <- sum(recommendations %in% relevant_movies)
precision <- retrieved_relevant / length(recommendations)
}
return(list(precision = precision, recall = recall))
}
# Example usage
recommendations <- recommend_movies_tfidf(movies_data, "Toy Story (1995)", 5)
print(recommendations)
precision_recall <- calculate_precision_recall(recommendations, ratings_data, movies_data)
print(precision_recall)
ui <- fluidPage(
titlePanel("Movie Data Analysis"),
sidebarLayout(
sidebarPanel(
selectInput("selected_movie", "Choose a Movie:", choices = unique(movies_data$title)),
numericInput("num_recommendations", "Number of Recommendations:", value = 5, min = 1, max = 20),
actionButton("recommend", "Get Recommendations"),
textOutput("precision_recall")
),
mainPanel(
tabsetPanel(
tabPanel("Most Common Genres", plotOutput("genrePlot")),
tabPanel("Movies Per Year", plotOutput("yearPlot")),
tabPanel("Ratings Distribution", plotOutput("ratingPlot")),
tabPanel("Most Rated Movies", plotOutput("mostRatedPlot")),
tabPanel("Recommendations", verbatimTextOutput("recommendationOutput"))
)
server <- function(input, output) {
output$genrePlot <- renderPlot({
ggplot(genre_analysis, aes(x = reorder(genres, n), y = n)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Most Common Movie Genres", x = "Genre", y = "Count")
})
output$yearPlot <- renderPlot({
ggplot(year_distribution, aes(x = year, y = n)) +
geom_line(color = "blue") +
labs(title = "Number of Movies Released Per Year", x = "Year", y = "Count")
})
output$ratingPlot <- renderPlot({
ggplot(rating_distribution, aes(x = rating, y = n)) +
geom_bar(stat = "identity", fill = "red") +
labs(title = "Distribution of Ratings", x = "Rating", y = "Count")
})
output$mostRatedPlot <- renderPlot({
ggplot(most_rated_movies, aes(x = reorder(title, n), y = n)) +
geom_bar(stat = "identity", fill = "purple") +
coord_flip() +
labs(title = "Top 10 Most-Rated Movies", x = "Movie", y = "Number of Ratings")
})
observeEvent(input$recommend, {
recommendations <- recommend_movies_tfidf(movies_data, input$selected_movie, input$num_recommendations)
output$recommendationOutput <- renderText({ paste("Recommended Movies:", paste(recommendations, collapse = ", ")) })
precision_recall <- calculate_precision_recall(recommendations, ratings_data, movies_data)
output$precision_recall <- renderText({ paste("Precision:", precision_recall$precision, "Recall:", precision_recall$recall) })
})
}
shinyApp(ui, server)
rsconnect::quartoPath()
install.packages("rsconnect")
